\section{Background}
To perform experiments with the \HICANNX{} \ASIC{} several steps are necessary:
\begin{enumerate}
\item The components of the \ASIC{} such an the parameters controlling the behaviour of its neurons and synapses have to be configured.
\item Some form of input data has to be transmitted to the \ASIC{}, which is then processed by it.
\item Data generated during this processing is transmitted to the \FPGA{}.
\end{enumerate}
Communication with the \ASIC{} happens in a real-time fashion as the time continuous analog emulation performed by the \ASIC{} cannot be paused and continued arbitrarily. Accordingly input data in the form of neuron events has to be transmitted to the \ASIC{} with precise timing and the timing of neuron events received back from the \ASIC{} has to be measured precisely.
The scheduling of event transmission and the timestamping of the received events on the \FPGA{} is realized by the \pbexec{} module on the \FPGA{}.

To perform an experiment the host computer generates a sequence of instructions. This sequence of instructions contains the operations necessary to configure the \ASIC{} and contains instructions that control the timing and content of events to be transmitted to the \ASIC{}.
This sequence of instructions, called \PlaybackProgram{}, is then processed by the \pbexec{} with a timing resolution of $\SI{8}{\nano\second}$.
Events received from the \ASIC{} are timestamped with the same resolution.

The high speed interface used for the communication between the \ASIC{} and the \FPGA{} is made up out of sixteen \LVDS{} lanes, eight for each direction that are able to operate at up to $\SI{2}{\giga\bit\per\second}$ for a total of $\SI{16}{\giga\bit\per\second}$ of full duplex bandwidth.

This thesis will focus mainly on the network attached accelerator deployment. In this case the \FPGA{} is connected to a host computer over a network connection.

The current network attached accelerator deployment used by the Electronic Vision(s) group called \BSSTwo{}-Cube\autocite{ref:bss_cube} uses a \Xilinx{} \Kintex7{} \FPGA{} and \LVDS{} lanes of the \ASIC{} are operated at $\SI{1}{\giga\bit\per\second}$. The host and the \FPGA{} communicate using the \UDP{} protocol over \Gigabitethernet{}. A custom automatic repeat request (ARQ) protocol\autocite{ref:hostarq} developed by the Electronic Vision(s) group is used to ensure reliable and ordered transmission of a stream of \PhyWordSize{} words over the unreliable and unordered \UDP{} protocol. In this thesis this protocol will be called \HostARQ{} hereafter.

Because the bandwidth between the host computer and the \FPGA{} is far smaller than the bandwidth between the \FPGA{} and the \ASIC{} the \PlaybackProgram{} as well as the received neuron events need to be buffered by the \FPGA{}. This is aided by the connection of the \FPGA{} to a external \DDR{} memory with a size of \DDRSIZE{}.
\autoref{fig:schematic_overview} gives an overview over the interaction between the host computer, the \FPGA{} and its communication with the \HICANNX{} \ASIC{}.

In the following \autoref{sec:interfaces} and \autoref{sec:pb_exec} a more detailed overview of the \FPGA{} design and especially the \pbexec{} is given. Afterwards \autoref{sec:old-pb-trace-management} gives a detailed description of the current buffer implementation for the \PlaybackProgram{} and the neuron events. It furthermore outlines the general requirements of this buffer such as the required data rate and highlights the problems of the current implementation.

These requirements are used to design a new implementation of the buffer for the \PlaybackProgram{} and the neuron events described in \autoref{sec:impl}. Finally, \autoref{sec:results} will compare the old and new buffer implementation in detail.

\begin{figure}
\centerline{\includegraphics{diagrams/cropped/fpga_overview}}
\caption{Schematic overview of the FPGA design facilitating the communication between a network attached host computer and a \HICANNX{} \ASIC{}. The host computer communicates with the \FPGA{} using the \UDP{} based \HostARQ{} protocol. The \PlaybackProgram{}s received by the \FPGA{} are stored in the playback and trace buffer and are executed using the \pbexec{}. Execution by the \pbexec{} generates events and control messages that are transmitted to the \ASIC{}. Events received from the \ASIC{} are timestamped by the \pbexec{} and stored in the trace buffer until they are sent to the host.}\label{fig:schematic_overview}
\end{figure}


\subsection{\AXI{} and stream interfaces}\label{sec:interfaces}
\subsubsection{Stream-Interfaces}
Many components of the old and the new \FPGA{} design are connected using stream interfaces. Stream interfaces provide an unidirectional transfer of data from one component to another.
Throughout this thesis two different stream interfaces, \AXIStream{} and the \ValidNextStream{} will be encountered.
The \AXIStream{} interface is a standard interface used by many of the components provided by \Xilinx{} used by the old and the new buffer design. The \ValidNextStream{} interface is used by many of the components developed by the Electronic Vision(s) group, such as the \pbexec{}.

The \AXIStream{} interface connects a single Transmitter to a single Receiver to transport a unidirectional data stream from the Transmitter to the Receiver . An \AXIStream{} consists of at least five signals:
\begin{itemize}
    \item \ACLK{} is the clock signal used by the stream. All other signals will be sampled on the rising edge of this clock.
    \item \ARESETn{} is the reset signal used by the stream. It is active low.
    \item \TDATA{} is the signal carrying the data word. It is a multiple of eight bits wide and driven by the Transmitter.
    \item \TVALID{} is a single bit signal driven by the Transmitter indicating that valid data is present on the \TDATA{} signal.
    \item \TREADY{} is a single bit signal driven by the Receiver indicating that it can accept data.
\end{itemize}
The relation of \TDATA{}, \TVALID{} and \TREADY{} is governed by a set of rules.
Data is transferred from the Transmitter to the Receiver when \TREADY{} and \TVALID{} are driven high simultaneously.
Furthermore, a Transmitter is not allowed to wait for the Receiver to drive \TREADY{} high before asserting \TVALID{}. The Receiver, on the contrary, is allowed to wait for the Transmitter to drive \TVALID{} high before asserting \TREADY{}.
When both the Transmitter and the Receiver can process the data fast enough, data can be transferred on every clock cycle. When this is the case \TREADY{} and \TVALID{} will be driven high continuously.
\AXIStream{} defines a set of further signals that can extend the functionality of this stream interface. In this thesis two optional signals will be relevant.
The first is \TKEEP{}. \TKEEP{} has one bit for every eight bits contained in the \TDATA{} signal and is driven by the Transmitter to indicate which bytes of the \TDATA{} signal contain valid data.
If bit $n$ of \TKEEP{} is driven high, bits $8n$ to $8(n + 1) - 1$ of \TDATA{} will contain valid data, if it is driven low the data contained in these bits is to be ignored by the Receiver.
The second optional signal that will be encountered is \TLAST{}. This is a single bit that is driven by the Transmitter which indicates that the current transfer is the last transfer of a packet.

The second stream type encountered in this thesis is used by many of the components of the \FPGA{} design that were developed by the Electronic Vision(s) group. It is for example used by the \pbexec{}. In this thesis it will be referred to as \ValidNextStream{}. It is closely related to \AXIStream{}, but replaces the \TREADY{} signal with a \NEXT{} signal.
This is a single bit signal driven by the Reciever to indicate that the current data was processed, and the Transmitter can present the next data word on \TDATA{}. Furthermoren it has different rules regarding \TVALID{} and \NEXT{} compared to the rules of regarding \TVALID{} and \TREADY{}.
For a \ValidNextStream{} the Transmitter is allowed to wait until the Receiver drives \NEXT{} high before asserting \TVALID{}.

This different rule set means that in general an \AXIStream{} and a \ValidNextStream{} cannot be connected together by simply connecting the \TREADY{} and the \NEXT{} signals as they can deadlock. For example when connecting a \ValidNextStream{} Transmitter to an \AXIStream{} Receiver, the \ValidNextStream{} Transmitter is allowed to wait until the \AXIStream{} Receiver drives \TREADY{} (connected to \NEXT{}) until it drives \TVALID{}. However, the \AXIStream{} Receiver is allowed to wait until \TVALID{} is driven high before asserting \TREADY{}. In this case both the Receiver and the Transmitter will wait forever, and no progress will be made. This means when connecting a \ValidNextStream{} Transmitter to an \AXIStream{} Receiver, one has to use an \AXIStream{} Receiver that will assert \TREADY{} without waiting until \TVALID{} is asserted by the Transmitter. Connecting incompatible Receivers and Transmitters can be achieved by inserting a suitable adapter, like a \SKIDBuffer{}.

\subsubsection{AXI}\label{sec:AXI}
\AXI{}\autocite{ref:axi} is a standard protocol used for communication between some components of the \FPGA{} design. It allows for communication between a single Manager and a Subordinate. Compared to a stream interface it provides bidirectional data transport and additional signals controlling source and target of the data that is transmitted. While the old playback and trace buffer designtIt is only used for communication between the \DDR{} controller and the playback and trace buffer, it will be used for more components in the new playback and trace buffer design.
The basic operations of the \AXI{} protocol are memory mapped read and write transactions.
The \AXI{} protocol uses an \ACLK{} and an \ARESETn{} signal that play the same role as they do in an \AXIStream{} as well as five independent channels:
\begin{itemize}
  \item The \AW{} channel transmits information about a write from the Manager to the Subordinate. This information contains the address and the number of words that will be written (the \burstsize{}).
  \item The \AR{} channel transmits information about a read from the Manager to the Subordinate. This information contains the address and the number of words that should be read (the \burstsize{}).
  \item The \W{} channel transmits the data that is written from the Manager to the Subordinate.
  \item The \R{} channel transmits the data that is read from the Subordinate to the Manager.
  \item The \B{} channel transmits a response that contains the result of a write from the Subordinate to the Manager
\end{itemize}
Each of these channels uses the same handshaking signals \READY{} and \VALID{} as well as rules of an \AXIStream{}. Furthermore, the \W{} and \R{} channels use a \LAST{} signal to indicate the last word of a burst.

Using these five channels read and write transactions are performed. A read transaction is initiated by the Manager by transmitting the address and the number of words that should be read on the \AR{} channel. The subordinate then responds with the corresponding data on the \R{} channel. A write transaction transmits the address that should be written to and the number of words that should be written on the \AW{} channel  and the data that should be written on the \W{} channel. The Subordinate responds with the result of a write transaction one the \B{} channel once it is completed.

Every channel operates separately from each other. This means that for example the data to be written can be transmitted by the Manager on the \W{} channel before the address information is transmitted on the \AW{} channel. A Manager is also allowed to transmit a second read on the \AR{} channel before having received the answer to the first.
From this it follows that the maximum data rate supported by the bus specification is a single data word each clock cycle on both the read and write channels. The actual achievable data rate depends on the specific implementation of the Manager and the Subordinate.

\subsection{Playback Executor}\label{sec:pb_exec}
The \pbexec{} is responsible for processing the instruction stream that is received from the playback buffer as well as receiving, time stamping and transmission to the trace buffer of events from the \ASIC{}. \autoref{diagram:executor} shows a schematic overview of this module. This section will only give a brief overview of this module, a more detailed description can be found in \autocite{ref:pb_exec}.

The instructions that are processed by the executor can broadly be categorized into the three different categories:
\begin{itemize}
\item Instructions in the \readCat{} perform read operations on the several buses connected to the \pbexec{} and result in response data that is sent to the trace stream.
\item Instructions of the \writeCat{} perform writes to these buses.
\item Instructions of the \waitCat{} are used to pause the processing of the instruction stream until a specific event takes place. This can for example be the elapsing of a specific duration or the completion of a read.
\end{itemize}
A special instruction, the \haltInstr{} is used to delineate separate experiments from each other. The \haltInstr{} marks the end of a \PlaybackProgram{} and is looped back to the trace data where it can be used to differentiate trace data belonging to different \PlaybackProgram{}s.

There are numerous sources like the result data of instructions in the \readCat{} and the events received from the \ASIC{} for trace data that are transmitted by the \pbexec{} on the trace stream. The data from these different sources is combined into the single trace stream using an arbiter, the trace arbiter, which uses a combination of round-robin and priority arbitration.

The \pbexec{} operating at a \pbExecClock{} clock rate. The number of clock cycles that are required to process a instruction depends on the specific instruction that is processed, however for every instruction atleast one clock cycle is required. In other words the highest theoretical rate of instructions that the \pbexec{} can process is one instruction every clock cycle. Similar to the instruction stream the \pbexec{} can also emit at most a single trace word every clock cycle.

Both the playback instruction stream and the trace data are fundamentally streams of variable size words. For transmission and reception over the fixed width \HostARQ{} streams they are encoded using \UT{} encoding scheme\autocite{karasenko2020neumann}.

For the playback instruction stream this encoding is performed on the host. On the \FPGA{} the \pbexec{} decodes the instruction stream before processing it.
Likewise, the trace data generated by the \pbexec{} is encoded by the \pbexec{} before being sent to the trace stream.

The encoding and decoding also operates at a \pbExecClock{} clock rate and can produce/consume at most one \PhyWordSize{} sized word per clock cycle.

This means the maximum data rate at which the playback stream can be processed and the maximum data rate that is sent on the trace stream is
\[\PhyWordSize{} · \pbExecClock{} = \pbExecBandwidth{}\]

\begin{figure}
\centerline{\includegraphics{diagrams/cropped/executor_detail}}
\caption{Overview of the \pbexec{}. The \pbexec{} receives a \UT{} encoded stream of instructions that is decoded by the \UT{} decoder. Each instruction is executed by the executor. Depending on the instruction this can for example cause an event to be sent to the \ASIC{} or a \JTAG{} operation to be performed. Data received from the \ASIC{} as well as data that is for example generated by instructions that are read from one of the other \FPGA{} buses is combined into a single variable word width stream by the trace arbiter and encoded into a fixed word width stream by the \UT{} encoder.
This overview is simplified and does not include all interfaces that the executor has access to. Furthermore, it does not include all sources for trace data.}\label{diagram:executor}
\end{figure}

\subsection{Playback and trace buffer}\label{sec:old-pb-trace-management}
The bandwidth between \FPGA{} and the \ASIC{} at \ASICBandwidth{} far exceeds the bandwidth between the host and the \FPGA{} of \HostBandwidth{}. To allow transmission and reception of the full data rate supported between the \FPGA{} and the \ASIC{} the \FPGA{} is connected to \DDRSIZE{} of \DDR{} memory that is used as buffer for the playback and trace data. This section will describe the current implementation of this playback and trace buffer and highlight its shortcomings. A schematic overview of the current design is shown in \autoref{diagram:detail_old}. The \FPGA{} design uses the \XilinxMIG{} to allow access to this \DDR{} memory using the \AXI{} protocol.

The playback and trace buffer has two responsibilities:
\begin{itemize}
  \item It stores the playback instructions stream received from the host into the \DDR{} memory and once a complete \PlaybackProgram{} was received reads the \PlaybackProgram{} from the memory and transmits it to the \pbexec{}
  \item It receives the trace data from the \pbexec{} and stores it to the \DDR{} memory until it is transmitted back to the host.
\end{itemize}

In the current \FPGA{} design it operates as a pair of \FIFO{}s. One for the playback stream and one for the trace stream. The input side of the playback buffer is a \ValidNextStream{} that appends to the already stored data. On the output side the data is transmitted to the \pbexec{} in the same order it was received. The trace buffer operates analogously with the input and the outside switched.

This \FIFO{} is implemented using the \Xilinx{} \VFIFO{} core, which implements a multichannel \FIFO{} backed by an \AXI{} accessible memory. It is connected to the \AXI{} interface of the \DDR{} controller. The \XilinxMIG{} is used as this \DDR{} controller. The \VFIFO{} core is used in a configuration using two channels. The first channel is used for the playback data and the second channel is used for the trace data.

The playback control block is responsible for scheduling the transmission of the playback instruction stream to the \pbexec{}.
It allows data to be transmitted from the \VFIFO{} to the \pbexec{} only when two conditions are fulfilled:
\begin{enumerate}
\item The first condition is that the \FIFO{} between the \VFIFO{} and the \pbexec{} is full or the \VFIFO{} channel for the playback data is empty.
\item The second condition is that the \VFIFO{} channel for the playback data is full or a \haltInstr{} was written to the \VFIFO{} but not transmitted to the \pbexec{} yet.
\end{enumerate}
When a complete \PlaybackProgram{} fits into the \VFIFO{} playback channel, these two conditions enforce that playback of the instructions that make up the \PlaybackProgram{} is only started once it was completely transmitted to the \VFIFO{}, as each \PlaybackProgram{} ends with a \haltInstr{}. This ensures that the rate of instructions that can be transmitted to the \pbexec{} is not limited by the slow \HostARQ{} interface but instead by the \VFIFO{} and indirectly by the \XilinxMIG{} interface speed.
When a \PlaybackProgram{} does not fit completely in the \VFIFO{} playback channel, playback of it is started whenever the \VFIFO{} playback channel is full. This means that depending on te rate the \pbexec{} is processing playback instructions it is possible that the \HostARQ{} interface can be the limiting factor for the playback rate.
The \VFIFO{} is configured with a burst size of \(\SI{2048}{\byte}\) and using $\num{8192}$ pages of $\SI{4}{\kibi\byte}$ allocated to each the playback and the trace channel, which means it can store at most \(\num{8192} · \SI{4}{\kibi\byte} = \SI{32}{\mebi\byte}\) per channel.

\begin{figure}
\centerline{\includegraphics{diagrams/cropped/detail_old}}
\caption{Schematic overview of the old, FIFO{}-based, module handling the playback and trace data. Data received from the host is bufferd in the \DDR{} memory and gated by the playback control to be transmitted to the \pbexec{} once at least one complete \PlaybackProgram{} was received from the host. In the opposite direction the trace data is stored in the \DDR{} memory until it is transmitted to the host.}\label{diagram:detail_old}
\end{figure}


This implementation of the playback and trace buffer has several shortcomings:
\begin{enumerate}
  \item It can only use \(\SI{64}{\mebi\byte}\) (\(\SI{32}{\mebi\byte}\) for the playback and \(\SI{32}{\mebi\byte}\) for the trace data) of the available $\DDRSIZE{}$ of memory\label{point:limited_size}
  \item The \FIFO{} interface prohibits reading a non-contiguous block of the received trace data
  \item The \FIFO{} interface precludes already transmitted \PlaybackProgram{} or parts of them to be reused.
  \item Allocation of the total memory to either playback memory or trace memory is fixed, changing the size of memory allocated to each of them requires generating a new \FPGA{} bitstream.
\end{enumerate}
The maximum size of the two \VFIFO{} channels can be increased by increasing the burst size and allocated pages up to a maximum of \(\SI{256}{\mebi\byte}\) (See table 4-1 in \autocite{ref:vfifo}), which is still only half of the total size of the memory.

A replacement for the playback and trace buffer should fulfill the following requirements
\begin{itemize}
  \item Use the complete $\DDRSIZE{}$ of available memory.
  \item Support the maximum possible data rate of $\pbExecBandwidth{}$ supported by the \pbexec{} when transferring the trace data from the \pbexec{} to the memory.
  \item Allow reuse of already transmitted playback instructions. Because the bandwidth between the host and the \FPGA{} is a lot smaller than the bandwidth between the \FPGA{} and the \ASIC{} this can increase the rate experiments can be performed.
  \item Allow out of order access to the received trace data. This can reduce the time required to transfer the relevant trace data from the \FPGA{} to the host, when not all trace data is relevant.  It furthermore allows for an increased level of introspection of the state of the \FPGA{}, especially in case of unexpected behaviour.
\end{itemize}
